## 第二章 神经网络的数学基础
### 2.0 概览 
> 张量，张量运算，微分，梯度下降，反向传播等
>
> 注：文中所写的代码只是笔者个人觉得要注意。并不全，需要完整代码的请参考书籍。
>
> 要显示数学公式请给浏览器装插件MathJax Plugin for Github（需要fq）

### 2.1 初识神经网络
#### 1.数据集
mnist数据集：将手写数字的灰度图像（28\*28像素）划分到10个类别里。  
测试集包含60000训练图像和10000张测试图像    

```python
from keras.datasets import mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

```py
>>> train_images.shape
(60000, 28, 28)
>>> len(train_labels)
60000
>>> train_labels
array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)
```



**类和标签的说明**
在分类问题中某个类别叫做类（class)，数据点叫做样本（sample）,某个样本对应的类叫做标签（label）

> 此数据集加载数据时进行分割(train_images,train_labels),(test_images,test_labels)=mnist.load_data()

#### 2.网络架构

**核心是构造层和编译**   

**层(layer)**,是一种数据处理模块，可以将他看成一个数据过滤器，进去一些数据，出来的数据更加有用。而神经网络就是有很多这样的层结构组成的数据处理的“筛子”   

本例中使用两个Dense层，也叫全连接层，最后一层为softmax层，是输出层，作用是将原本的输出值转换为概率值（总和为1），每一个概率表示分属于每一个类别的概率。本例有十个类别。 

```python
from keras import models
from keras import layers
network = models.Sequential()
network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))
network.add(layers.Dense(10, activation='softmax'))
```

  

**编译的三个重要参数**

- 损失函数（loss function):网络衡量训练数据性能的依据。即这次训练的结果好不好，有多好。  
- 优化器（optimizer）：根据训练数据和损失函数来更新网络的机制。(更新网络即调整参数)
- 训练、测试需要监控的指标（metric）：本例只指定了精度（accuracy）  

```python
network.compile(optimizer='rmsprop',
loss='categorical_crossentropy',
metrics=['accuracy'])
```

#### 3.数据预处理

神经网络每一层的数据要求必须是二维的，即（samples,features），即需要把多维的特征占平成一维。至于是否需要标准化或者其他处理，看实际情况。  最后需要对标签进行分类编码。

> 本例将[0,255]的取值范围收缩在[0,1]范围之内。

```pytho
# 准备图像数据
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype('float32') / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype('float32') / 255
# 标签分类编码
from keras.utils import to_categorical
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)
```

#### 4.开始训练

训练使用神经网络的fit方法。是一种拟合模型。需要注意几个参数。  

- epochs:只训练周期数，即一共要训练多少次，每一次都需要输入全部样本，但全部样本是分批次输入的，通过batch_size参数来指定，默认为32，一般是不需要变动的。  

```py
network.fit(train_images, train_labels, epochs=5, batch_size=128)
```

在测试集上评估性能，使用神经网络的evaluate方法。给出测试特征值和标签即可。  

```py
>>> test_loss, test_acc = network.evaluate(test_images, test_labels)
>>> print('test_acc:', test_acc)
test_acc: 0.9785
```

> 介绍两个概念：
>
> 1. 过拟合（overfit）：在测试集上的精度低于训练集。这通常是因为训练集上过分的拟合了某些特殊点，就好像如果在一堆有趋势的散点图里画趋势线时，过分去接触每个点，就会使得最后的趋势线弯弯曲曲，反而不能反映真是情况。本例子就属于这种
> 2. 欠拟合（underfit）：在训练集和测试集上表现都很差。因为训练的不够。

### 2.2 神经网络的数据表示

前面我们使用存储数据的numpy多维数据就是一种**张量**，这是一种**数据容器**，矩阵就是二维张量。将其推广至任意维度，就是各个维度的张量，比如三维就是一个体，需要注意，张量的维度称之为轴（axis）。

numpy使用ndim就可以查看轴的个数，轴的个数也叫阶。    

#### 2.2.1 标量（0D张量，D-demension即维度）

标量即一个数。

#### 2.2.2 向量（1D张量）

即一维数组。需要需注意的是，如果一个向量有5个元素，我们可以叫他为5D向量（不是5D张量），这里的维度就表示沿着某一个轴的元素个数，而非轴的个数。

#### 2.2.3 矩阵（2D张量）

矩阵的行(row)和列(column)分别对应轴0和轴1。

#### 2.2.4 3D及更高维度的张量

将多个矩阵组合成一个新的数组，可以得到一个3D 张量，你可以将其直观地理解为数字
组成的立方体。一般所用的都是0-5D张量。

#### 2.2.5 关键属性

- 轴的个数（阶）
- 形状（shape）：一个整数数组，记录了张量沿着每一个轴的维度大小（元素个数），标量的为空。
- 数据类型（dtype）：张量中所包含的数据类型。

```py
#给出张量train_images 的轴的个数，即ndim 属性。
>>> print(train_images.ndim)
3
#下面是它的形状。
>>> print(train_images.shape)
(60000, 28, 28)
#下面是它的数据类型，即dtype 属性。
>>> print(train_images.dtype)
uint8
```

这样解释比较好：（60000,28,28），有60000个矩阵，每一个矩阵包括28*28的数据，每一个矩阵都是灰度图像，这样60000个矩阵就构成了一个3D张量。

#### 2.2.6 在numpy中操作张量（非常重要）

对前面的例子来说，使用train_images[i]来选择沿着轴0，选择了特定的元素，这种操作叫对张量进行切片。

```pytho
>>> my_slice = train_images[10:100]
>>> print(my_slice.shape)
(90, 28, 28)
```

但是我觉得书上对于翻译的不是很准确，书上将上面的操作称之选择第10到100个数字。实际上是选择了第10到第100个矩阵，也就是本例样本。而非翻译所说的数字。下面的两种等价写法，更加证实了这一点。

```python
>>> my_slice = train_images[10:100, :, :]
>>> my_slice.shape
(90, 28, 28)
>>> my_slice = train_images[10:100, 0:28, 0:28]
>>> my_slice.shape
(90, 28, 28)
```

可以看到，实际上就是对于每一个轴分别进行切片，这样就可以得到任意我们想要的数据形式。

比如选出每张灰度图像右下角14*14的区域

```py
my_slice = train_images[:, 14:, 14:]
```

又比如选出图像中心的14*14的区域。使用负数索引：表示相对于末尾的相对位置，-1表示最后一个元素。-7表示倒数第七个元素。

```python
my_slice = train_images[:, 7:-7, 7:-7]
```

即：对于每一个矩阵，选择第8个到第22（28减去后面6个为索引22）个元素。**因为切片是左闭右开，所以切片的[a:b]就是选择的第a+1和第b个元素。**

#### 2.2.7 数据批量

前面我们说的batch_size就是指定批量。即每一次训练分多少批次输入样本。对于这种批量的轴0，称之为批量轴(batch axis)或者批量维度(batch dimension).而对于整个数据集的轴0，就有样本轴（samples axis)和样本维度(samples dimension)。

#### 2.2.8 现实张量

> 向量数据：2D 张量，形状为 (samples, features)。  
> 时间序列数据或序列数据：3D 张量，形状为 (samples, timesteps, features)。  
> 图像：4D张量，形状为(samples, height, width, channels)或(samples, channels,
> height, width)。  
> 视频：5D张量，形状为(samples, frames, height, width, channels)或(samples,
> frames, channels, height, width)。  

**向量张量**  

轴0表示样本轴，轴1表示特征轴。即向量张量就是一个二维的张量。（注意与向量表示1维张量区别）。

注意一个数据集用什么张量存储不是取决于某一个样本有几个特征，而是这些特征可不可以放在一个维度里。比如

> 人口统计数据集，其中包括每个人的年龄、邮编和收入。每个人可以表示为包含 3 个值
> 的向量，而整个数据集包含100 000 个人，因此可以存储在形状为(100000, 3) 的2D
> 张量中。  
> 文本文档数据集，我们将每个文档表示为每个单词在其中出现的次数（字典中包含
> 20 000 个常见单词）。每个文档可以被编码为包含20 000 个值的向量（每个值对应于
> 字典中每个单词的出现次数），整个数据集包含500 个文档，因此可以存储在形状为
> (500, 20000) 的张量中。

这两个例子就可以用2D张量存储。而上面的例子，每一个图像必须用矩阵来存储，那么他就是3D张量。

**时间序列数据或序列数据**

有些数据可能有时间需求或其他的类似需求。就可以将数据存储在3D张量里，一般序列都存在轴1上，比如

![alt 图片](./images/time_data.jpg "图1")



- 股票价格数据集：每一分钟，记录三个特征（当前价格、前一分钟最高价格、前一分钟最低价格），这样每一分钟就是一个3D向量，一天就是个（390,3）的2D张量，一个交易日假设390分钟，那么250天的数据就可以存储为一个（250,390,3）的3D张量。
- 推文数据集：推特一条推文最大字长为280字符。那么对于一条推文而言，将其编码为280个字符的序列。（其实就是一个个的单词），每一个单词又是由128个字符组成的，这样一个单词采用（0，1）编码，即出现了某字符就填1，否则填0，这样一个单词就是一个128D向量，一条推文就是（280,128）的2D张量，而很多推文就是一个（n,280,128)的3D张量。

**图像数据**

图像一般这样存放。（样本，高度，宽度，颜色深度），即(samples,height,width,colir_depth),需要注意颜色深度的位置可以放最后（TensorFlow用的），也可以放在样本轴后（theano用）。  

灰度图像的颜色深度为1，可以省略，那么灰度图像的每一个样本就可以存放于一个2D张量中。  

再有，还会用通道来描述颜色深度，（channels)。

![alt 图片](./images/4d-tensor-image.jpg "图2")

**视频数据**

视频数据是有一系列帧，每一帧都是一张彩色的图像。那么显然就是（samples，frames，height，width，color_depth).

### 2.3 神经网络的核心：张量运算

前面我们提到深度学习是由很多层构建起来的，每一层都相当在做变换，对数据做变换，数据是用张量存储的，那么我们所做的变换都是对张量所做的变换。

现在先探讨一些理论的知识，后面会给出张量运算的几何解释。

**理论的相关知识**

看例子的第一层处理  

```python
keras.layers.Dense(512,activation='relu')
```

这一层的代码解释为输入一个2D张量，返回另一个2D张量。具体的运算：  

> output=relu(dot(W,input)+b)  dot表示点积运算，relu(x)=max(x,0)

这里的input是一个2D张量，像这样,轴0表示samples，纵轴表示features
$$
\begin{bmatrix}
{a_{11}}&{a_{12}}&{a_{13}}&{\cdots}&{a_{1784}} \\\\  
{a_{21}}&{a_{22}}&{a_{23}}&{\cdots}&{a_{2784}} \\\\  
{\vdots}&{\vdots}&{\vdots}&{\ddots}&{\vdots} \\\\  
{a_{600001}}&{a_{600002}}&{a_{600003}}&{\cdots}&{a_{60000784}}
\end{bmatrix} \tag{1}
$$
而W也是2D张量，和b都是该层的属性，也是我们以后要学习的参数。

W是这样的一个东西，w的行数表示一个神经元有多少权重系数，这取决于输入数据即矩阵1的列数，而列数表示这一层要将这个数据转换为多少类别。比如这里的512。也就是神经元的个数。
$$
\begin{bmatrix}
{w_{11}}&{w_{12}}&{\cdots}&{w_{1512}} \\\\  
{w_{21}}&{w_{22}}&{\cdots}&{w_{2512}} \\\\  
{\vdots}&{\vdots}&{\ddots}&{\vdots} \\\\  
{w_{7841}}&{w_{7842}}&{\cdots}&{w_{784512}} 
\end{bmatrix} \tag{2}
$$
然后他们做点积：
$$
\begin{bmatrix}
{y_{11}}&{y_{12}}&{\cdots}&{y_{1512}} \\\\  
{y_{21}}&{y_{22}}&{\cdots}&{y_{2512}} \\\\  
{\vdots}&{\vdots}&{\ddots}&{\vdots} \\\\  
{y_{6w1}}&{y_{6w2}}&{\cdots}&{y_{6w512}} 
\end{bmatrix} \tag{3}
$$
再加上列向量b，同样b的行数等于矩阵1的列数。最后得到的矩阵再使用激活函数relu进行处理，就得到了这一层的输出2D张量（命名为矩阵4）。他将作为在下一层的张量运算的输入。

> 备注：后面几节阐述的张量点积类比矩阵点积就可以了。还需要注意的是广播和逐个元素处理。矩阵4和向量b是如何相加的呢？首先要做的就是广播。
>
> 1. 向较小的张量添加轴（叫作广播轴），使其ndim 与较大的张量相同。
> 2.  将较小的张量沿着新轴重复，使其形状与较大的张量相同。
>
> 比如（30,10）和（10，）相加会先将（10，）扩展为（1,10）*（想想为什么不是（10,1）*然后再将每一列复制为30次。就得到了（30，10）。这就叫做广播，他们就可以相加了。
>
> 另外一个就是逐个元素处理了，举个简单的例子，两个矩阵的逐个元素相乘，就是对应位置的元素乘起来，注意这不是矩阵做点乘。上面的relu就是逐元素处理。可以简单实现为  
>
> ```py
> def naive_relu(x):
> assert len(x.shape) == 2
> x = x.copy()
> for i in range(x.shape[0]):
> for j in range(x.shape[1]):
> x[i, j] = max(x[i, j], 0)
> return x
> ```
>
> 不过实际上numpy内部支持了这种批量操作。只需要简单一句就可以实现  
>
> ```py
> import numpy as np
> z = x + y
> z = np.maximum(z, 0.)
> ```
>
> 

#### 2.3.1 张量变形

之前使用的是展平层处理第一次输入的数据，因为神经网络要求输入数据必须是（samples，features）的。我们也可以使用numpy的reshape直接处理后在输入，即：  

```py
train_images = train_images.reshape((60000, 28 * 28))
```

#### 2.3.2 张量运算几何解释

张量中的某个元素可以看做某位几个空间的坐标，将其和原点连起来就是一个某维向量，这样对其运算就是在对向量做几何变换。

#### 2.3.3 深度学习的几何解释

神经网络有一系列的张量运算构成，那么神经网络就可以解释为高维空间里很复杂的几何变换，这种变换可以通过很多简单的步骤来实现。  

![alt 图片](./images/神经网络的几何解释.jpg)

让纸球恢复平整就是机器学习的内容：为复杂的、高度折叠的数据流形找到简洁的表示。现在你应该能够很好地理解，为什么深度学习特别擅长这一点：它将复杂的几何变换逐步分解为一长串基本的几何变换，这与人类展开纸球所采取的策略大致相同。深度网络的每一层都通过变换使数据解开一点点——许多层堆叠在一起，可以实现非常复杂的解开过程。

### 2.4 神经网络训练能成功的秘诀：基于梯度的优化

每一层做的事，类似于这样

```py
output=relu(dot(W,x)+b)
```

W和b都是张量，是这一层的属性，将之称之为权重矩阵和偏置向量。对应于kernel和bias。最开始的时候是随机的，然后我们根据反馈信号来调节这两个属性。这就是**学习**。  

> 上述过程相信描述为这样  
>
> 1. 抽取训练样本x和对应目标y组成的数据批量。  
> 2. 在网络上使用x进行运行，得到预测值y_pred，这一步叫做前向传播。  
> 3. 计算预测值y_pred和y之间的距离（即损失）
> 4. 更新网络的所有权重，使得网络在这批数据上的损失略微下降。  

前三步前面已经解决了，第四步呢？一个很低效但是可行的方案是每一次根据损失函数来猜测性的变更权重矩阵的某个参数，然后再计算损失函数，再比较，如此反复调整。  

更好的解决方案是：我们能够找到某一个办法可以找到某个确定的调整权重矩阵的方式，而不是一次次的猜测。基于此猜想，我们首先看看导数和梯度。  

根据高等数学知道，y=f(x)的导数反映了函数值y在某点处的变化率，在某一点上，我们如果要使得函数值减小一点，则方向很明显是沿着导数的反方向上走一段距离。将一元函数推广至多元函数，就相当于在曲面上下降，而下降的方向是无穷个的，其中下降最快的就是梯度。  

<img src="./images/导数.jpg" alt="图片" style="zoom:50%;" />

<img src="./images/梯度.jpg" alt="图片" style="zoom:50%;" />

现在讨论多元函数的梯度。公式是这样的，我们去掉了b向量，因为这个对我们分析梯度没有影响。

```python
y_pred=dot(W,x)
loss_value=loss(y_pred,y)
```

我们之前设定的epochs，那么每一次的训练是样本特征x和标签y都是不变的。所以将上面结合起来，损失函数是权重矩阵的单射。即有  

```python
loss_value=f(W)
```

类比于一元函数，假设W 的当前值为W0。f 在W0 点的导数是一个张量gradient(f)(W0)，其形状与W 相同，每个系数gradient(f)(W0)[i, j] 表示改变W0[i, j] 时loss_value 变化的方向和大小。张量gradient(f)(W0) 是函数f(W) = loss_value 在W0 的导数。前面已经看到，单变量函数f(x) 的导数可以看作函数f 曲线的斜率。同样，gradient(f)
(W0) 也可以看作表示f(W) 在W0 附近曲率（curvature）的张量。对于一个函数f(x)，你可以通过将x 向导数的反方向移动一小步来减小f(x) 的值。同样，对于张量的函数f(W)，你也可以通过将W 向梯度的反方向移动来减小f(W)，比如W1 =W0 - step * gradient(f)(W0)，其中step 是一个很小的比例因子。也就是说，沿着曲率的反方向移动，直观上来看在曲线上的位置会更低。注意，比例因子step 是必需的，因为gradient(f)(W0) 只是W0 附近曲率的近似值，不能离W0 太远。

#### 2.4.1 随机梯度下降

根据上面我们知道了给定数据，我们可以建立一个损失方程loss=f(W,x),然后可以找到梯度f'(W,x),但是沿着梯度方向下降多少才会使得损失函数最少呢？以及找到了损失函数，如何求得权重矩阵呢？  

我们只能试，也就是每次下降一点点，然后去计算损失函数，根据损失函数是否减少的反馈在进一步调整W，每一次计算出损失函数就计算梯度以便于下一次使用。步骤是这样的：  

> 1. 抽取训练样本x和对应目标y组成的数据批量。 
> 2. 运行网络，得到预测值y_pred。  
> 3. 计算损失函数。  
> 4. 计算损失对网络参数的梯度（反向传播）。  
> 5. 将参数沿着梯度的反方向移动一点，比如W-=step*gradient,从而减小损失。
>
> 

这里有几个需要注意的点。  

1. step表示学习率，即步长，他意味着每一次沿着梯度方向下降多少。这很关键，太小导致训练次数过多，而且有可能进入到局部最低点，太大可能导致在最小值周围震荡。 

   ![图片](./images/梯度下降.jpg)

2. 刚才我们描述的方法叫小批量随机梯度下降，即每一次训练的每一批只随机选取一部分数据。与之对应还有一次一个样本的真批量sgd，以及全部数据的批量sgd。而这种解决通过沿着梯度下降的方向寻找损失函数最小值的方法叫做优化方法或者优化器。
3. 我们最后的W是在最开始的W一次次减下来得到的，为什么要这么做？因为未知数太多了，我们不可能通过使用建立起导数=0的方式来解出这个方程来求出权重矩阵。
4. 从上面第四步可以知道，反向传播其实就是根据损失函数来调整权重矩阵的反馈机制。

#### 2.4.2 链式求导：反向传播算法

根据上面的推导可知，可以通过损失函数计算权重矩阵。在实际的神经网络中，有很多层，写成公式就是：  

```python
f(W1,W2,W3)=a(W1,b(W2,c(W3))) # a,b,c都是算子
```

那么我们就可以通过链式法则。从损失函数计算出梯度。这种算法叫反向传播，他的实质就是从最终损失开始，从最顶层反向作用于最底层（反馈机制），而在计算梯度过程里就可以得到每一个参数对于损失值的贡献大小。里面的具体细节先不深究，暂时理解到这里即可。

### 2.5 运用所学的只是回看开头的例子，加深印象

### 2.6 本章小结

> - 学习是指找到一组模型参数，使得在给定的训练数据样本和对应目标值上的损失函数最小化。  
> - 学习的过程：随机选取包含数据样本及其目标值的批量，并计算批量损失相对于网络参数的梯度。随后将网络参数沿着梯度的反方向稍稍移动（移动距离由学习率指定）。  
> -  整个学习过程之所以能够实现，是因为神经网络是一系列可微分的张量运算，因此可以利用求导的链式法则来得到梯度函数，这个函数将当前参数和当前数据批量映射为一个梯度值。  
> -  后续几章你会经常遇到两个关键的概念：损失和优化器。将数据输入网络之前，你需要先定义这二者。  
> - 损失是在训练过程中需要最小化的量，因此，它应该能够衡量当前任务是否已成功解决。  
> - 优化器是使用损失梯度更新参数的具体方式，比如 RMSProp 优化器、带动量的随机梯度下降（SGD)等。
